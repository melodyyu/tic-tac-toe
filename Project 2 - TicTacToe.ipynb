{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tic Tac Toe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u> Description <u> \n",
    "In this implementation of a 4x4 tic-tac-toe game, we will use two reinforcement learning (RL) algorithms: Q-Learning and temporal difference(TD). We begin by describing the major components.\n",
    "\n",
    "- **Agent** <br>\n",
    "Player 1 and player 2.\n",
    "\n",
    "- **Environment** <br> \n",
    "The board will be initialized as a 4x4 grid containing only zeroes. When player places their piece, the position will be updated with 1 if the move came from player 1 and -1 if the move came from player 2. \n",
    "\n",
    "- **State** <br>\n",
    "The board state (current piece placements and available spaces) of the agent and its opponent. \n",
    "\n",
    "- **Actions** <br>\n",
    "The positions that a player can choose based on the current board state. At each position, players can either play a piece or cannot (the piece is in use by the opponent). Players will take turns placing pieces and will continue until terminal state is reached. The position they place a piece will be randomly selected from the open positions.\n",
    "\n",
    "- **Terminal state** <br>\n",
    "Players cannot move anymore (the board is filled and/or a win/lose/draw condition has been reached). \n",
    "\n",
    "- **Reward** <br>\n",
    "The player receives +1 reward if they win, -1 reward if they lose and 0 reward if they draw. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>Environment<u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOARD_ROWS = 4\n",
    "BOARD_COLS = 4\n",
    "\n",
    "PLAYER_X = 1 \n",
    "PLAYER_0 = 0 \n",
    "\n",
    "##initialize board \n",
    "class Environment:\n",
    "    def __init__ (self):\n",
    "        self.board = np.zeros((BOARD_ROWS, BOARD_COLS))\n",
    "        self.board_state = None\n",
    "        self.state = state\n",
    "        self.terminal = False #bool - game signals terminal state\n",
    "        self.player_symbol = PLAYER_X\n",
    "        self.p1 = p1\n",
    "        self.p2 = p2\n",
    "         \n",
    "    #returns position at specific location \n",
    "    def get_position (self, x, y):\n",
    "        return self.board[x][y] #note: [x][y] == [x,y]\n",
    "    \n",
    "    #set position (i.e, update state) at specific index to player's symbol\n",
    "    def set_position (self, x, y, player_symbol):\n",
    "        self.board[x][y] = player_symbol\n",
    "#         if ((x > 4) or (y > 4) or (x < 0) or (y < 0)): \n",
    "#             print(\"you're outta bounds sir\")\n",
    "        \n",
    "    def print_board(self):\n",
    "        print(self.board)\n",
    "        \n",
    "    #reshape current board state to store into state-value dictionary\n",
    "    def save_state(self):\n",
    "        self.board_state = str(self.board.reshape(BOARD_COLS * BOARD_ROWS))\n",
    "        return self.board_state   \n",
    "        \n",
    "    #return if position is open \n",
    "    def check_open(self, x, y):\n",
    "        #position was empty, return T;\n",
    "        if (self.board[x][y] == 0): \n",
    "            return True \n",
    "        else: \n",
    "            #position was filled, return F \n",
    "            return False \n",
    "    \n",
    "    #determine winner; if agent wins, return 1. if opponent wins, return -1. \n",
    "    def winner(self):\n",
    "        \n",
    "        winner = None \n",
    "\n",
    "        #horizontal win -- player gets 4 in a row across\n",
    "        for i in range(BOARD_ROWS):\n",
    "            if sum(self.board[i, :]) == 4:\n",
    "                self.terminal = True\n",
    "                winner = 1\n",
    "            if sum(self.board[i, :]) == 0:\n",
    "                self.terminal = True\n",
    "                winner = -1\n",
    "\n",
    "        # vertical win -- player gets 4 in a column \n",
    "        for i in range(BOARD_COLS):\n",
    "            if sum(self.board[:, i]) == 4:\n",
    "                self.terminal = True\n",
    "                winner = 1\n",
    "            if sum(self.board[:, i]) == 0:\n",
    "                self.terminal = True\n",
    "                winner = -1\n",
    "        \n",
    "        # diagonal win \n",
    "        diag_sum1 = sum([self.board[i, i] for i in range(BOARD_COLS)])\n",
    "        diag_sum2 = sum([self.board[i, BOARD_COLS-i-1] for i in range(BOARD_COLS)])\n",
    "        diag_sum = max(diag_sum1, diag_sum2)\n",
    "        if diag_sum == 4:\n",
    "            self.terminal = True\n",
    "            winner = 1\n",
    "        if diag_sum == 0:\n",
    "            self.terminal = True\n",
    "            winner = -1\n",
    "        \n",
    "        # tie -- no more available positions\n",
    "        if len(self.open_positions()) == 0:\n",
    "            self.terminal = True\n",
    "            winner = 0\n",
    "      \n",
    "        # if the game has not ended, simply return nothing \n",
    "        self.terminal = False\n",
    "        print(\"Winner is: \", winner)\n",
    "        return winner\n",
    "            \n",
    "\n",
    "#     #determine reward based on winner\n",
    "#     def reward(self): \n",
    "#         result = self.winner() \n",
    "        \n",
    "#         #agent won\n",
    "#         if (result == 1): \n",
    "            \n",
    "#         #opponent won\n",
    "#         if (result == -1):\n",
    "            \n",
    "#         #tie -- no reward \n",
    "            \n",
    "    \n",
    "    #return an array of open positions in the board\n",
    "    def open_positions(self): \n",
    "        positions = [] \n",
    "        for x in range(BOARD_ROWS):\n",
    "            for y in range(BOARD_COLS):\n",
    "                if self.board[x,y] == 0:\n",
    "                    positions.append((x,y))\n",
    "        return positions\n",
    "        \n",
    "    #clear board, reset all positions to 0\n",
    "    def reset(self): \n",
    "        self.board = np.zeros((BOARD_ROWS, BOARD_COLS))\n",
    "        self.terminal = False\n",
    "        self.playerSymbol = AGENT_SYMBOL\n",
    "    \n",
    "    #update state to next state, place piece into position on board\n",
    "    def update_state(self, position):\n",
    "        self.board[position] = self.player_symbol\n",
    "        \n",
    "        #switch with other player \n",
    "        if self.player_symbol == 1:\n",
    "            self.player_symbol == -1\n",
    "        else:\n",
    "            self.player_symbol == 1\n",
    "        \n",
    "    #print board\n",
    "    def show_board(self):\n",
    "        # p1: x  p2: o\n",
    "        for i in range(0, BOARD_ROWS):\n",
    "            print('-------------')\n",
    "            out = '| '\n",
    "            for j in range(0, BOARD_COLS):\n",
    "                if self.board[i, j] == 1:\n",
    "                    token = 'x'\n",
    "                if self.board[i, j] == -1:\n",
    "                    token = 'o'\n",
    "                if self.board[i, j] == 0:\n",
    "                    token = ' '\n",
    "                out += token + ' | '\n",
    "            print(out)\n",
    "        print('-------------')\n",
    "        \n",
    "    # give reward only when game ends\n",
    "    def give_reward(self):\n",
    "        result = self.winner()\n",
    "        # backpropagate reward\n",
    "        if result == 1:\n",
    "            self.p1.feedReward(1)\n",
    "            self.p2.feedReward(0)\n",
    "            self.terminal == True\n",
    "        elif result == -1:\n",
    "            self.p1.feedReward(0)\n",
    "            self.p2.feedReward(1)\n",
    "            self.terminal == True\n",
    "        else:\n",
    "            self.p1.feedReward(0.1)\n",
    "            self.p2.feedReward(0.5)\n",
    "        \n",
    "    #train the agent to play \n",
    "    def play(self, rounds=100):\n",
    "        #print number of rounds, go by thousands\n",
    "        for i in range(rounds):\n",
    "            if i%1000 == 0:\n",
    "                print(\"Rounds {}\".format(i))\n",
    "            \n",
    "            #agent plays game againsts itelf\n",
    "            while not self.isEnd:\n",
    "                # Player 1\n",
    "                positions = self.check_open()\n",
    "                p1_action = self.p1.chooseAction(positions, self.board, self.playerSymbol)\n",
    "                # take action and upate board state\n",
    "                self.updateState(p1_action)\n",
    "                board_hash = self.getHash()\n",
    "                self.p1.addState(board_hash)\n",
    "                # check board status if it is end\n",
    "\n",
    "                win = self.winner()\n",
    "                if win is not None:\n",
    "                    # self.showBoard()\n",
    "                    \n",
    "                    # ended with p1 either win or draw\n",
    "                    self.give_reward()\n",
    "                    self.p1.reset()\n",
    "                    self.p2.reset()\n",
    "                    self.reset()\n",
    "                    break\n",
    "\n",
    "                else:\n",
    "                    # Player 2\n",
    "                    positions = self.check_open()\n",
    "                    p2_action = self.p2.chooseAction(positions, self.board, self.playerSymbol)\n",
    "                    self.updateState(p2_action)\n",
    "                    board_hash = self.getHash()\n",
    "                    self.p2.addState(board_hash)\n",
    "\n",
    "                    win = self.winner()\n",
    "                    if win is not None:\n",
    "                        # self.showBoard()\n",
    "                        # ended with p2 either win or draw\n",
    "                        self.give_reward()\n",
    "                        self.p1.reset()\n",
    "                        self.p2.reset()\n",
    "                        self.reset()\n",
    "                        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSILON = 0.3\n",
    "GAMMA = 0.9\n",
    "LEARNING_RATE = 0.2\n",
    "\n",
    "\n",
    "class Player:\n",
    "    def __init__ (self):\n",
    "        self.name = name\n",
    "        self.states = [] #stores action and position taken\n",
    "        self.Env = Environment() \n",
    "        self.gamma = GAMMA\n",
    "        self.epsilon = EPSILON\n",
    "        self.learning_rate = LEARNING_RATE\n",
    "        self.terminal = self.Env.terminal #determine when to move to next state \n",
    "                \n",
    "        self.q_values = {} #store q_values as [state][action] in dictionary\n",
    "        \n",
    "        for i in range(BOARD_ROWS):\n",
    "            for j in range(BOARD_COLS):\n",
    "                self.Q_values[(i, j)] = {}\n",
    "                for p in open_positions():\n",
    "                    self.q_values[(i,j)][p] = 0\n",
    "                    \n",
    "        \n",
    "        \n",
    "    def choose_action(self, positions, current_board, symbol):\n",
    "        #choose action with most expected value \n",
    "        next_reward = 0\n",
    "        \n",
    "        #take a random action, store that action into positions \n",
    "        if (np.random.uniform(0,1) <= self.epsilon):\n",
    "            index = np.random.choice(len(positions))\n",
    "            action = positions[index]\n",
    "        \n",
    "        #take a greedy action\n",
    "        else: \n",
    "            max_value = -999\n",
    "            for p in positions:\n",
    "                #keep copy of current states \n",
    "                next_board = current_board.copy()\n",
    "                next_board[p] = player_symbol\n",
    "                next_board_state = self.save_state(next_board)\n",
    "                \n",
    "                current_position = self.Env.state \n",
    "                next_reward = self.q_values[current_position][p]\n",
    "                \n",
    "                if self.q_values.get(next_board_state) is None:\n",
    "                    value = 0\n",
    "                else: \n",
    "                    self.q_values.get(next_board_state)\n",
    "                print(\"value\", value)\n",
    "                \n",
    "                if value >= max_value:\n",
    "                    max_value = value\n",
    "                    action = p\n",
    "      \n",
    "        print(\"{} takes action{}\".format(self.name, action))\n",
    "        return action \n",
    "        \n",
    "    def play(self, rounds=10):\n",
    "        i=0\n",
    "        \n",
    "        while i < rounds:\n",
    "            \n",
    "            if self.Env.terminal:\n",
    "\n",
    "                #back propagate reward \n",
    "                reward = self.Env.give_reward()\n",
    "\n",
    "                for p in self.positions:\n",
    "                    self.q_values[self.Env.state][p] = reward\n",
    "                print(\"Game End Reward\", reward)\n",
    "\n",
    "                for s in reversed(self.states):\n",
    "                    current_q_value = self.q_values[s[0]][s[1]]\n",
    "                    reard = current_q_value + self.learning_rate * (self.gamma * reward - current_q_value)\n",
    "                    self.q_values[s[0]][s[1]] = round(reward, 3)\n",
    "\n",
    "                self.reset()\n",
    "                i+=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
